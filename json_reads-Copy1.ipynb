{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file is 20GB - preview\n",
    "JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "preview = pd.read_csv(r'C:\\Users\\philip.lawson\\Desktop\\kaggle\\train_v2.csv',nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the above in a function for other json columns\n",
    "def json_column_cleaner(table_name,column_name,append = True):\n",
    "    table_name[column_name] = table_name[column_name].apply(json.loads) # surplus\n",
    "    df_dict = {}\n",
    "    for i in np.arange(0,table_name.shape[0]):\n",
    "        normed = json_normalize((table_name[column_name][i]))\n",
    "        df_dict[i] = normed\n",
    "    \n",
    "    # remove empty dataframes\n",
    "    df_dict_copy = df_dict.copy()\n",
    "    for i,j in df_dict_copy.items():\n",
    "        if j.empty:\n",
    "            df_dict.pop(i)\n",
    "    \n",
    "    flattened_lookup = pd.concat(df_dict.values())\n",
    "    flattened_lookup.index = df_dict.keys()\n",
    "    \n",
    "    # testing part\n",
    "    \n",
    "    if append == True:\n",
    "        merged_table = table_name.merge(flattened_lookup,how='left',left_index=True,right_index=True)\n",
    "        return merged_table\n",
    "    else:\n",
    "        return flattened_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_column_cleaner(table_name,column_name,append = True):\n",
    "    table_name[column_name] = table_name[column_name].apply(ast.literal_eval) # surplus\n",
    "    df_dict = {}\n",
    "    for i in np.arange(0,table_name.shape[0]):\n",
    "        normed = json_normalize((table_name[column_name][i]))\n",
    "        df_dict[i] = normed\n",
    "    \n",
    "    # remove empty dataframes\n",
    "    df_dict_copy = df_dict.copy()\n",
    "    for i,j in df_dict_copy.items():\n",
    "        if j.empty:\n",
    "            df_dict.pop(i)\n",
    "    \n",
    "    flattened_lookup = pd.concat(df_dict.values())\n",
    "    flattened_lookup.index = df_dict.keys()\n",
    "    \n",
    "    # testing part\n",
    "    \n",
    "    if append == True:\n",
    "        merged_table = table_name.merge(flattened_lookup,how='left',left_index=True,right_index=True)\n",
    "        return merged_table\n",
    "    else:\n",
    "        return flattened_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_data_dict(colname,save = 0):\n",
    "    col_input = pd.read_csv(r'C:\\Users\\philip.lawson\\Desktop\\kaggle\\train_v2.csv',usecols = [colname])\n",
    "    column_read = json_column_cleaner(pd.DataFrame(col_input[colname].unique(),columns = [colname]),colname,False)\n",
    "\n",
    "    unq_val_count = lambda x: x.unique().shape[0]\n",
    "    value_counts = column_read.apply(unq_val_count,axis = 0)\n",
    "    \n",
    "    single_vals = column_read[value_counts[value_counts == 1].index.values].apply(np.unique,axis = 0).T\n",
    "    \n",
    "    if save == 1:\n",
    "        single_vals.to_csv(r'C:\\Users\\philip.lawson\\Desktop\\kaggle\\{}_json_single_values.csv'.format(colname))\n",
    "        value_counts.to_csv(r'C:\\Users\\philip.lawson\\Desktop\\kaggle\\{}_json_values.csv'.format(colname),header = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# other_column_cleaner(preview,'hits')\n",
    "device = pd.read_csv(r'C:\\Users\\philip.lawson\\Desktop\\kaggle\\train_v2.csv',usecols = ['device'])\n",
    "\n",
    "device = json_column_cleaner(pd.DataFrame(device.device.unique(),columns = ['device']),'device',False)\n",
    "\n",
    "unq_val_count = lambda x: x.unique().shape[0]\n",
    "dev_value_counts = device.apply(unq_val_count,axis = 0)\n",
    "dev_value_counts.to_csv(r'C:\\Users\\philip.lawson\\Desktop\\kaggle\\dev_json_values.csv')\n",
    "\n",
    "single_vals = device[dev_value_counts[dev_value_counts == 1].index.values].apply(np.unique,axis = 0).T\n",
    "single_vals.to_csv(r'C:\\Users\\philip.lawson\\Desktop\\kaggle\\dev_json_single_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = {}\n",
    "ignore_cols['device'] = list(dev_value_counts[dev_value_counts == 1].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We have 6 JSON columns containing multiple other columns\n",
    "2. We have a visitStartTime which appears to be a UNIX timestamp and equal to visitId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_dict('geoNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philip.lawson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\philip.lawson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "json_data_dict('totals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\philip.lawson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\philip.lawson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "json_data_dict('trafficSource')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
